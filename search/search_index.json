{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SOMOSPIE Documentation","text":"<p>Welcome to the documentation for the  SOMOSPIE Library!</p> <p>SOil MOisture SPatial Inference Engine (SOMOSPIE) is a data-driven tool designed to improve the representation of soil moisture. It addresses the limitations of remote sensing (i.e., satellites), such as coarse resolution and spatial gaps, through various machine learning algorithms based on meaningful terrain features.</p> <p>SOMOSPIE supports reproducibility, explainability, and portability of results, contributing to FAIR principles. Its use of containerization and methods usable with publicly available datasets allows users to use and experiment with SOMOSPIE easily.</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<ul> <li>\u2699\ufe0f Installation: Learn how to install SOMOSPIE for various software environments.</li> <li>\ud83d\udcd6 Data Guide: Learn about what type of data to use and how it should be prepared.</li> <li>\ud83c\udf0d Soil Moisture Prediction: Learn about the machine learning methods used to estimate soil moisture at high resolution.</li> <li>\u2728 Additional Features: Explore all of the other functionalities of SOMOSPIE. </li> </ul>"},{"location":"#features","title":"\ud83e\uddf0 Features","text":"<ul> <li>\ud83d\udef0\ufe0f  Retrieve/Download Satellite Data - Fetch coarse-resolution soil moisture datasets from satellites (ESA-CCI). </li> <li>\u2702\ufe0f Crop to Region of Interest - Define an area of interest for efficient and localized analysis.</li> <li>\ud83d\udd0d Predict Missing Values and Downscale: Fill spatial gaps and downscale to a finer resolution with various machine learning algorithms. </li> <li>\ud83d\udcca Analysis and Visualization: Generate statistical outputs and visual maps for interpretation and evaluation. </li> </ul>"},{"location":"additional_features/","title":"Additional Features","text":"<p>SOMOSPIE features a variety of additional features, including optional preprocessing options, data fetching, and visualization/analysis tools. This guide demonstrates how to use any of these additional features to increase model accuracy, or analyze of results. </p>"},{"location":"additional_features/#data-preprocessing","title":"\ud83e\uddf9 Data preprocessing","text":"<p>SOMOSPIE features optional preprocessing steps that potentially boost the accuracy of results. These include dropping columns in a prepared dataset, and Joint Principal Component Analysis. </p>"},{"location":"additional_features/#joint-principal-component-analysis-joint-pca","title":"Joint Principal Component Analysis ( joint PCA)","text":"<p>Joint PCA is a statistical method that analyzes multiple related datasets. It finds common patterns of variation across the datasets by training a model. The model identifies the relationships between variables and uses these relationships to reduce the dimensions of a dataset. <code>joint_pca.py</code> utilizes this model to remove original features from training and prediction data, replacing them with fewer columns called principal components. This helps capture the important features of the original variables.</p> <p>Joint PCA can be run through the Python script <code>joint_pca.py</code>, using: <pre><code>python3 ./joint_pca.py IN_TRAIN IN_PREDI OUT_TRAIN OUT_PREDI LOG_FILE\n</code></pre></p>"},{"location":"additional_features/#feature-engineering","title":"Feature Engineering","text":"<p>To reduce the dimensionality of training datasets, columns can be dropped according to the user's needs. The Python script <code>drop_cols.py</code> accomplishes this by allowing users to specify which columns to keep and drop. </p> <p>To drop columns, run the python script <code>drop_cols.py</code> using: <pre><code>python3 ./drop_cols.py [input_file] [output_file] -k [cols_to_keep] -d [cols_to_drop]\n</code></pre></p> <p>Note</p> <p>Use -d to drop columns, or -k to specify columns to keep. Do not use both. </p>"},{"location":"additional_features/#data-fetching","title":"\ud83d\udce1 Data Fetching","text":"<p>SOMOSPIE features a collection of methods to retrieve data, including several shell scripts, which fetch and save relevant data locally. These methods are located within the <code>SOMOSPIE/data_readers/satellite</code> repository, and use shell to fetch the corresponding variables. </p>"},{"location":"additional_features/#fetching-soil-moisture","title":"Fetching Soil Moisture","text":"<p><code>fetch_soil_moisture.sh</code> fetches and saves ESA_CCI soil moisture data for each day of a specified year; it is saved into the data directory, in a directory <code>ESA_CCI/{year}/</code>. Fetch soil moisture can be run through the command <code>./fetch_soil_moisture.sh [YEAR]</code></p> <p>Warning</p> <p>Fetching soil moisture through <code>fetch_soil_moisture.sh</code> can take up to 30 minutes.</p>"},{"location":"additional_features/#fetching-terrain-parameters","title":"Fetching Terrain Parameters","text":"<p>Terrain parameters can be fetched from HydroShare. <code>fetch_topo_predictors.sh</code> does this by fetching a specified terrain parameter one at a time as a .prj, .sdat, and .sgrd file. It can be run using: <code>./fetch_topo_predictors.sh topo_predictors [$TOPO]</code>. Topographic features are saved within data/topo_dir/. For a list of valid terrain parameters to fetch, see Data Preparation.</p>"},{"location":"additional_features/#fetching-ecoregions","title":"Fetching Ecoregions","text":"<p><code>fetch_ecoregions.sh</code> retrieves CEC ecoregion shapefiles at each available level (I-III). It saves each ecoregion within its own directory; for example, level I CEC ecoregions are saved to <code>NA_Terrestrial_Ecoregions_Level_I_Shapefile/</code>. The script does not require any arguements and can be run using <code>./fetch_ecoregions.sh</code>. </p> <p>Within the Satellite directory, there also exists a reg_list.csv file, which contains labels describing each region's title. </p>"},{"location":"additional_features/#analytics-and-visualization","title":"\ud83d\udcc8 Analytics and Visualization","text":""},{"location":"additional_features/#compare-observations-to-estimations","title":"Compare Observations to Estimations","text":"<p>extracts the soil moisture predictions from the predictions and compares them to the observed soil moisture at said point, computing R<sup>2</sup> and MSE. These can be used as metrics for how well a model performed at making soil moisture predictions. <code>obs_vs_pred.R</code> performs these evaluations and can be called using:</p> <pre><code>./obs_vs_pred.R [observed_value_file] [prediction_file] [R^2 file] [rmse_output_file]\n</code></pre>"},{"location":"additional_features/#plotting-dataframes","title":"Plotting dataframes","text":"<p>The <code>somosplot.py</code> script provides a variety of visualization tools for SOMOSPIE. Users can visualize soil moisture data using various plot types, such as: </p> <ul> <li>Histograms</li> <li>Soil maps</li> <li>Heat-maps</li> </ul> <p>Any prepared .csv file can be plotted using the command line structure:</p> <pre><code>python3 ./somosplot.py [input_file] -c [has_header] -o [output_file] -p [plot_type] -t \"[plot_title]\" -s [point_size] -d [dependent_column_index] -m [min_value] -M [max_value]\n</code></pre>"},{"location":"data_guide/","title":"Data Guide","text":"<p>SOMOSPIE is built upon publicly available datasets that describe:</p> <ul> <li>Remotely-sensed coarse soil moisture</li> <li>Terrain Parameters (covariates)</li> <li>Eco-regionalization of North America</li> </ul>"},{"location":"data_guide/#soil-moisture-data","title":"\ud83d\udca7 Soil Moisture Data","text":"<p>The first data point needed for SOMOSPIE is coarse soil moisture datasets (SM). Publicly available soil moisture data is available from the European Space Agency Climate Change Initiative (ESA-CCI) project from 1979 to 2020, hosted at: https://www.esa-soilmoisture-cci.org. </p>"},{"location":"data_guide/#custom-soil-moisture-data","title":"Custom Soil Moisture Data","text":"<p>SOMOSPIE also allows the use of local files. The data must match the following specifications. While multiple formats are supported, GeoTIFF and CSV files are recommended for optimal compatibility. </p> <p>Provided Formats</p> <ul> <li>NetCDF (.nc) files for soil moisture for each day of a provided year. Must be stacked into soil moisture data for each month of the year. </li> </ul> <p>Other Acceptable Formats</p> <ul> <li>rds, tif, &amp; sdat files stackable in R with stack()</li> <li>Comma-separated .csv or .txt files</li> </ul> <p>Datasets must include two columns specifying longitude and latitude coordinates, and at least one column containing soil moisture values.</p> <p>Example of a Dataset </p> Index Latitude Longitude Soil Moisture 0 -101.375 37.125 0.1121 1 -101.125 37.125 0.1603 ... ... ... ... 479 -103.000 33.625 0.3485 <p>Soil Moisture Data Fetching and Preprocessing</p> <ul> <li>Section \"Preparing Soil Moisture Data\" of Data Preparation elaborates on soil moisture preprocessing methods.</li> <li>Section \"Fetching Soil Moisture Data\" of Additional Features explains how to install the provided soil moisture data from ESA-CCI. </li> </ul>"},{"location":"data_guide/#terrain-parameters","title":"\u26f0\ufe0f Terrain Parameters","text":"<p>Terrain parameters, also known as covariates, are values that describe the physical features and landscape of the Earth. GEOtiled is a library built for SOMOSPIE that, when provided with Digital Elevation Models (DEMs) representing the Earth's elevation, determines various terrain parameters, such as slope, aspect, and hillshade. These parameters are directly utilized by SOMOSPIE, serving as inputs to the machine learning algorithms and therefore as predictors of soil moisture. The final soil moisture estimates will be the same size as the provided terrain parameters, which may range in spatial resolution from kilometers to meters.</p> <p>The terrain parameters should be in raster format, such as .tif, where they will eventually be merged with soil moisture data for model fitting/training. </p> <p>SM Data Fetching and Preprocessing</p> <ul> <li>Section \"Preparing Terrain Parameters Data\" of Data preparation elaborates on preprocessing steps for terrain parameters. </li> <li>Section \"Fetching Terrain Parameters\" of Additional Features elaborates on how to fetch and download pre-computed terrain parameters.</li> </ul>"},{"location":"data_guide/#ecoregion-boundaries","title":"\ud83c\udf10 Ecoregion Boundaries","text":"<p>We utilize the 2011 Commission for Environmental Cooperation (CEC) ecoregion dataset to define the spatial limits of soil moisture estimates. This dataset divides North America into polygon-based ecoregions at three levels. Levels I through III are used to describe similarity within each region. Level I ecoregions are larger and encapsulate the smaller Level II regions. Using the higher-level regions results in speedups from a smaller region of interest. </p> <p> Level I ecoregions (left) and Level III ecoregions (right) - Source</p> <p>For large-scale runs of SOMOSPIE, we recommend defining a region of interest. The Data Preparation Guide provides instructions on how soil moisture data and terrain parameters can be cropped to an ecoregion. </p>"},{"location":"data_preparations/","title":"Data Preparation and Preprocessing","text":"<p>SOMOSPIE supports a variety of preprocessing functions, which allow users to modify custom data before being used by machine learning algorithms. Once the data has been downloaded, it should be preprocessed using the following methods. </p> <p>Note</p> <ul> <li>All preprocessing methods are found within the directory <code>SOMOSPIE/code/preprocessing/</code>. </li> <li>The Data Guide elaborates on the data necessary for SOMOSPIE.</li> <li>The data must be downloaded. This guide assumes data is within a directory located at <code>SOMOSPIE/data</code>.</li> <li>See the \"Data Fetching\" section of Additional Features for a guide on how to fetch data.</li> </ul>"},{"location":"data_preparations/#preparing-soil-moisture-data","title":"Preparing Soil Moisture Data","text":"<p>Soil moisture data should be obtained from the European Space Agency Climate Change Initiative (ESA-CCI) soil moisture dataset. This dataset captures the available soil moisture at a 27km x 27km resolution for the entire world, allowing for accurate reading of the data for a specified year; however, some gaps may appear due to various factors. The data is formatted as a NetCDF (.nc) file for each day for a specified year. </p> <p>Once downloaded, the data can be preprocessed from daily soil moisture data into monthly soil moisture data within the specified year using <code>extract_SM_monthly.R</code>. This results in a structured dataset similar to the following:</p> Column Description Example x Longitude location -101.375 y Latitude location 37.125 X1 Soil moisture average for January 0.112 X2 Soil moisture average for February 0.160 ... ... ... X12 Soil moisture average for December 0.349 Table 1: example results of extract_SM_monthly.R <p>The data will be available in an .rds format, which is eventually be converted into a .csv file with added terrain parameters. </p> <p>Example Command: <pre><code>./extract_SM_monthly.R 2017\n</code></pre></p>"},{"location":"data_preparations/#preparing-terrain-parameters","title":"Preparing Terrain Parameters","text":""},{"location":"data_preparations/#accessing-terrain-parameters-data","title":"Accessing Terrain Parameters Data","text":"<p>Terrain parameters can be obtained in two ways: GEOtiled or HydroShare. GEOtiled is an open-source software that efficiently generates terrain parameters from Digital Elevation Models (DEMs). For more information on generating terrain parameters using GEOtiled, please visit GEOtiled.</p> <p>HydroShare contains a dataset \"Explanatory Variables and DEMs,\" whose columns describe the following terrain parameters, all of which can be used within SOMOSPIE.</p> Parameter Description Units Terrain Aspect The orientation of the terrain slope Radians Catchment Area Specific catchment area, the area from which rainfall flows into a river, lake, or reservoir Square meters Channel Network Base Level Channel network base level, the distance of each pixel to the highest surrounding elevation Meters Distance to Channel Network Distance from each pixel to the nearest channel network, stream, or river Meters Convergence Index Convergence index obtained by averaging the bias of the slope directions of adjacent cells from the central cell, subtracting 90\u00b0 -90\u00b0 to +90\u00b0 Horizontal Curvature Plan curvature, the curvature of the hillside in a horizontal plane. Indicates concavity or convexity of terrain Unitless (centered at 0) DEM, Elevation Digital elevation model 1x1km Meters above sea level Length Slope Factor Length of constant slopes from-to a given point Meters Relative Slope Position Position of relative height maxima as a function of slope. 0 = valley floor, 100 = ridge top Continuous (0\u2013100) Analytical Hillshading Representation of topographic relief simulating the effect of natural light on the surface Adimensional Filtered DEM Elevation data after identifying and filling surface depressions for hydrologic analysis Meters above sea level Terrain Slope The change of elevation relative to horizontal distance; measure of steepness or inclination Radians Valley Depth Index Interpolation of channel network base level elevation and subtraction from original elevations Meters Vertical Curvature Profile curvature intersecting the plane defined by the Z axis and the maximum gradient. Positive = convex, negative = concave Unitless (centered at 0) Topographic Wetness Index Indicator of likelihood of saturated soil during rain events and sediment/matter accumulation Adimensional Table 2: acceptable terrain features accepted from HydroShare"},{"location":"data_preparations/#coarsifying-terrain-parameters-optional","title":"Coarsifying Terrain Parameters [Optional]","text":"<p>With terrain parameters downloaded, an optional step is to coarsen the parameters, which will ultimately result in quicker soil moisture predictions at the cost of resolution. The resolution can be coarsened by an integer factor greater than 1. This is not a necessary step, as the data can be used at its native resolution. The script <code>coarsify.R</code> coarsens the resolution through the command: <code>./coarsify.R [input_file] [output_file] [aggregation_factor]</code>. </p> <p>Example Command: Scaling the resolution by a factor of 5 <pre><code>./coarsify.R topo.tif coarse_topo.tif 5\n</code></pre></p>"},{"location":"data_preparations/#reprojecting-the-raster-data","title":"Reprojecting the Raster Data","text":"<p>The raster file including the terrain parameters should be standardized to the WGS84 format, which uses the geographic coordinate system (longitude/latitude). The file may already be in this format, but for safety, it is recommended to reproject the raster to ensure compatibility. </p> <p>To reproject the raster, run <code>./reproject_raster.R [Input_files] [Output_files]</code> in the command line.</p> <p>Example Command: <pre><code>./reproject_raster.R ../data/topo_predictors/${topo}.tif ../data/topo_predictors/${topo}.tif`. \n</code></pre></p> <p>Warning</p> <p><code>reproject_raster.R</code> is currently deprecated; the required R library PlotKML is deprecated. </p>"},{"location":"data_preparations/#stacking-the-raster-data","title":"Stacking the Raster Data","text":"<p>The terrain parameters come as multiple raster files that describe each terrain parameter. These features need to be combined into a single file that encapsulates all features into a raster format. Merging the files into a single file is performed through a raster stack, which stacks the terrain parameters into a single raster. </p> <p>To make the raster stack, run the command <code>./make_raster_stack.R [output_directory] [input_files]</code>.</p> <p>Example Command: <pre><code>./make_raster_stack.R ./topo_predictors/ ./data/topo15_CONUS_1km.tif Analytical_Hillshading.tif Aspect.tif \n</code></pre></p>"},{"location":"data_preparations/#preparing-ecoregions","title":"Preparing Ecoregions","text":""},{"location":"data_preparations/#creating-ecoregion-shape","title":"Creating Ecoregion Shape","text":"<p>Ecoregions can be obtained from the Commission for Environmental Cooperation (CEC) website. They should be downloaded as a shapefile. Other options for ecoregion preparation include states and boxes. These ecoregions must be converted to an .rds shape file through <code>create_shape.R</code> before proceeding. To create this .rds file, run:<code>./create_shape.R [region_type] [region] [output_path]</code>.</p> <p>Example 1: Using the state of Arizona <pre><code>./create_shape.R STATE ARIZONA ./data/shapes/Arizona.rds\n</code></pre> Example 2: Using CEC level III region 10.2.4 <pre><code>./create_shape.R CEC 10.2.4 ./data/shapes/CEC_10_2_4.rds\n</code></pre> Example 3: Using a box to set an ecoregion <pre><code>./create_shape.R BOX -120_-110_30_40 ./data/shapes/box.rds\n</code></pre></p>"},{"location":"data_preparations/#creating-the-final-dataset","title":"Creating the Final Dataset","text":""},{"location":"data_preparations/#merging-soil-moisture-and-terrain-parameters","title":"Merging Soil Moisture and Terrain Parameters","text":"<p>With the prepared soil moisture stack and terrain parameters stack, the two files can be combined into one .csv file for training. Combining the files is done through the R script <code>add_topos.R</code>. The script can be run through the command line using: <pre><code>./add_topos.R [soil_moisture_file] [covariates_stack_file] [output_file] [terrain_parameters (optional)]\n</code></pre> Example Command:  <pre><code>./add_topos.R soil_moisture.rds cov.tif prepared_data.csv SLOPE ASPECT HILLSHADING\n</code></pre></p>"},{"location":"data_preparations/#cropping-to-ecoregion","title":"Cropping to Ecoregion","text":"<p>It is recommended to crop data to the region of interest defined by the ecoregions. Doing so results in substantial speedups for SOMOSPIE and requires significantly less memory than working on a large, uncropped area. Cropping the prepared data is done through the <code>crop_to_shape.R</code> script, using the previously created shapefile. It accepts the prepared dataset, along with the prepared ecoregion shape as parameters.</p> <p>Example Command: <pre><code>./crop_to_shape.R prepared_data.csv ./data/shapes/CEC_10_2_4.rds prepared_data_cropped.csv\n</code></pre></p>"},{"location":"data_preparations/#example-of-the-final-dataset","title":"Example of the Final Dataset","text":"<p>Below is a generated train.csv file for the state of Oklahoma:</p> Index Longitude Latitude Soil Moisture Elevation Aspect Slope 0 -101.375 37.125 0.112136401 960 1.435353398 0.002797498 1 -101.125 37.125 0.160304278 911 1.291842222 0.002738319 2 -100.875 37.125 0.184895456 863 1.106565714 0.004054314 ... ... ... ... ... ... ... 450 -94.125 33.625 0.348578483 91 4.439002514 0.004484821 Table 3: prepared dataset"},{"location":"installation/","title":"SOMOSPIE Installation Guide","text":"<p>SOMOSPIE is a scalable model used for predicting soil moisture. This guide explains how to install and run SOMOSPIE using one of the three supported methods:</p> <ol> <li>Using your local machine \ud83d\udcbb</li> <li>Using a virtual machine on Jetstream \u2601\ufe0f</li> <li>Using a Docker container \ud83d\udc33</li> </ol>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Prerequisites</p> <p>Downloading with any of the below methods will include the required dependencies. </p> <pre><code>- Anaconda-py3\n- Java 11\n- Jupyter Notebook\n- R\n- Spark\n- Python\n    - numpy\n    - pandas\n    - sklearn\n    - argparse\n    - pickle\n    - random\n    - itertools\n    - scipy\n    - matplotlib\n    - pyspark\n    - GRASS\n    - GDAL=3.8.4\n</code></pre>"},{"location":"installation/#using-your-local-machine","title":"\ud83d\udcbb Using Your Local Machine","text":"<p>The installation is only supported on Debian and Debian-based Linux distributions with Anaconda installed.  The script below installs all the necessary packages (R&gt;4, R libraries, Java 11, Spark, pip, Python Libraries)</p> <p><pre><code>git clone --recursive https://github.com/TauferLab/SOMOSPIE.git\ncd SOMOSPIE/install\n./install.sh\nsource ~/.bashrc\n</code></pre> To open the repository, enter the project root and run: <pre><code>jupyter lab\n</code></pre></p>"},{"location":"installation/#using-a-virtual-machine-vm-on-jetstream","title":"\u2601\ufe0f Using a Virtual Machine (VM) on Jetstream","text":"<p>To create a VM with the SOMOSPIE image, which includes all the necessary software stack:</p> <ol> <li>Go to\u00a0https://js2.jetstream-cloud.org\u00a0and login using \"XSEDE Globus Auth\" option.</li> <li>On any allocation go to Compute &gt; Instance and click on \"Launch Instance\".</li> <li>Follow this guide from\u00a0Jetstream2 Documentation\u00a0to adjust the configuration options on the instance, but on the \"Source\" tab under \"Select Boot Source,\" make sure you choose \"Instance Snapshot\" and then pick \"SOMOSPIE on Ubuntu 22.04\" from the list.</li> <li>When the instance is launched and the status is Active, you can access the VM via SSH.</li> <li>Once you are inside the shell of your VM, you are ready to start using SOMOSPIE!</li> </ol> <p>To launch the SOMOSPIE Jupyter Notebook on your browser, you can ssh using Local Forwarding:</p> <pre><code>ssh -L 8000:localhost:8000 &lt;username&gt;@&lt;your_instance_ip&gt;\ncd SOMOSPIE\njupyter lab --ip 0.0.0.0 --port 8000 --allow-root\n</code></pre> <p>You can use\u00a0Jetstream cloud computer\u00a0image for SOMOSPIE titled\u00a0\"SOMOSPIE on Ubuntu 22.04\".</p>"},{"location":"installation/#using-a-docker-container","title":"\ud83d\udc33 Using a Docker Container","text":"<p>To pull the image from DockerHub <pre><code>docker pull globalcomputinglab/somospie\n</code></pre> To create a container of the image and run the container, run: <pre><code>docker run -it -P --name=somospie globalcomputinglab/somospie:&lt;optional-tag&gt;\n</code></pre> To have the container removed at the end of runtime, add the --rm flag to the command. </p> <p>If any R packages are not installed in the container, you can install the missing packages by executing the container as the root user and running the <code>install.R</code> script: <pre><code>docker start &lt;container_id&gt;\ndocker exec -u root -t -i &lt;container_id&gt; bash\nRscript work/install/install.R\n</code></pre></p>"},{"location":"soil_moisture_predictions/","title":"Soil Moisture Predictions","text":"<p>SOMOSPIE leverages five machine learning algorithms for soil moisture predictions. The data must be prepared into a .csv file according to the Data Preparation and Preprocessing Guide.</p> <p>Following the Data Guide can provide guidance on how to prepare data for the machine learning algorithm. Preprocessing should result in a single .csv file for training. Each model will estimate the soil moisture at a finer resolution.</p> <p>This guide provides a brief overview of various machine learning implementations and how to run them for soil moisture predictions. Each model accepts a variety of arguments tailored to its specific needs. Any machine learning algorithm mentioned can be run through the command line or within a Jupyter Notebook.</p>"},{"location":"soil_moisture_predictions/#k-nearest-neighbors","title":"K-Nearest Neighbors","text":"<p>Predicts the soil moisture at each training point based on the K-Nearest neighbors regression. It is a simple algorithm that performs better when considering more neighbors, at the cost of efficiency. It tends to be the least accurate and noisy model, and serves as a baseline.</p> <p>The K-Nearest Neighbors model can be run through the command line using:</p> <pre><code>python3 hyppo.py -t IN_TRAIN -e IN_EVAL -l LOG_FILE -m KNN -o OUT_PATH -k K\n</code></pre> <p>Parameters</p> Name Type Description Default IN_TRAIN string Path to the .csv input file containing training data. \u2014 IN_EVAL string Path to the .csv input file containing labeled evaluation data. \u2014 MODEL string Model to be used; KNN \u2014 LOG_FILE string Path to the outputted log file, defaults to the console. <code>console</code> OUT_PATH string Path of the model's resulting predictions. <code>None</code> K int Number of neighbors to consider for predictions <code>10</code>"},{"location":"soil_moisture_predictions/#kernel-weighted-k-nearest-neighbors","title":"Kernel Weighted K-Nearest Neighbors","text":"<p>A variant of K-Nearest neighbors that uses a kernel function to weigh neighbors based on proximity. Nearby neighbors have a greater influence on predicting the soil moisture at point X compared to far neighbors. The model also finds the optimal number of neighbors to consider, rather than requiring a prespecified quantity. This results in a more accurate and less noisy version of the K-Nearest Neighbors algorithm.</p> <p>The Kernel Weighted K-Nearest Neighbors model can be run through the command line using:</p> <pre><code>knn.py -t IN_TRAIN -e IN_EVAL -l LOG_FILE -o OUT_PATH -k K_CAP\n</code></pre> <p>Parameters</p> Name Type Description Default IN_TRAIN string Path to the .csv input file containing training data. \u2014 IN_EVAL string Path to the .csv input file containing labeled evaluation data. \u2014 LOG_FILE string Path to the outputted log file, defaults to the console. <code>console</code> OUT_PATH string Path of the model's resulting predictions. <code>None</code> K_CAP int Maximum number of neighbors to consider <code>20</code>"},{"location":"soil_moisture_predictions/#random-forest","title":"Random Forest","text":"<p>Uses an ensemble learning method, building a collection of decision trees, and predicting the resulting soil moisture values through a technique called bagging; bagging builds multiple trees based on subsets of the training dataset. When making a prediction, each decision tree is consulted, and the soil moisture prediction is the average of the predictions from each tree. It is built upon the Scikit-Learn RandomForestRegressor. The random forest model tends to be less noisy than K-Nearest Neighbors, but requires a higher starting resolution for data to generate enough decision trees for accurate predictions.</p> <p>The Random Forests model can be run through the command line using:</p> <pre><code>rf.py -t IN_TRAIN -e IN_EVAL -l LOG_FILE -o OUT_PATH -max_tree MAX_TREES\n</code></pre> <p>Parameters</p> Name Type Description Default IN_TRAIN string Path to the .csv input file containing training data. \u2014 IN_EVAL string Path to the .csv input file containing labeled evaluation data. \u2014 LOG_FILE string Path to the outputted log file, defaults to the console. <code>console</code> OUT_PATH string Path of the model's resulting predictions. <code>None</code> MAX_TREES int Maximum number of decision trees to explore. <code>2000</code>"},{"location":"soil_moisture_predictions/#hybrid-piecewise-polynomial-approach-hyppo","title":"Hybrid Piecewise Polynomial Approach (HYPPO)","text":"<p>Builds upon the traditional K-Nearest Neighbors model by allowing non-linear predictions. Instead of averaging the values of the K-Nearest Neighbors, it creates a polynomial function that fits the neighbors. The degree of the polynomial function is selected using cross-validation to optimize the model's accuracy. Using a polynomial regression allows HYYPO to capture complex relationships in the data, leading to higher accuracy, and frequently receiving a higher R<sup>2</sup> than previous models. This accuracy comes with a significantly higher computational cost due to the fitting of a polynomial model.</p> <p>HYPPO can be run through the command line using:</p> <pre><code>python3 hyppo.py -t IN_TRAIN -e IN_EVAL -l LOG_FILE -m HYPPO -o OUT_PATH -k K -D d\n</code></pre> <p>Parameters</p> Name Type Description Default IN_TRAIN string Path to the .csv input file containing training data. \u2014 IN_EVAL string Path to the .csv input file containing labeled evaluation data. \u2014 MODEL string Model to be used; HYPPO \u2014 LOG_FILE string Path to the outputted log file, defaults to the console. <code>console</code> OUT_PATH string Path of the model's resulting predictions. <code>None</code> K int Number of neighbors to consider for predictions <code>10</code> d int Maximum polynomial degree of the model. <code>3</code>"},{"location":"soil_moisture_predictions/#surrogate-based-modeling-sbm","title":"Surrogate-Based Modeling (SBM)","text":"<p>SBM utilizes a regression surrogate model to derive a polynomial function for predicting soil moisture. Instead of considering a set of neighbors, SBM is a global model that attempts to approximate the behavior of all available neighbors. It utilizes a surrogate model, which only performs computations on a small subset of the original dataset to achieve increased computational performance. Like HYPPO, it leverages cross-validation to determine optimal polynomial degrees, resulting in high accuracy.</p> <p>SBM can be run through the command line using:</p> <pre><code>python3 hyppo.py -t IN_TRAIN -e IN_EVAL -l LOG_FILE -m SBM -o OUT_PATH -k k -D d\n</code></pre> <p>Parameters</p> Name Type Description Default IN_TRAIN string Path to the .csv input file containing training data. \u2014 IN_EVAL string Path to the .csv input file containing labeled evaluation data. \u2014 MODEL string Model to be used; SBM \u2014 LOG_FILE string Path to the outputted log file, defaults to the console. <code>console</code> OUT_PATH string Path of the model's resulting predictions. <code>None</code> k int The number of folds in cross validation <code>10</code> d int Maximum polynomial degree of the model. <code>3</code>"},{"location":"soil_moisture_predictions/#running-in-jupyter-notebooks","title":"Running in Jupyter Notebooks","text":"<p>For interactive use, SOMOSPIE models can be executed within a Jupyter Notebook. This approach is consistent with the command line version, utilizing the same input data. However, instead of passing arguments through the command line, various Python methods are used to run the models. This allows for a flexible and interactive workflow.</p> <p><pre><code>model=\"knn\"\nfrom knn import *\n\n# Load and prepare training/testing/evaluation data \nx_train, y_train = ...\n\n# train kernel weighted k nearest neighbors model\nknn = train_knn(x_train, y_train, maxK)\n\n# validate the model\nvalidate_knn(knn, x_test, y_test)\n\n# Generate evaluation predictions\npredict_knn(x_predict, evaluation_data, output_data, knn)\n</code></pre> Example implementation in a Python notebook</p>"},{"location":"soil_moisture_predictions/#results-visualization","title":"Results Visualization","text":"<p>Results show varying levels of accuracy, noisiness, and smoothness</p>"},{"location":"Research/acknowledgements/","title":"Acknowledgements","text":"<p>SENSORY is funded by the National Science Foundation (NSF) under grant numbers\u00a0#1724843,\u00a0#1854312,\u00a0#2103836,\u00a0#2103845,\u00a0#2138811, and\u00a0#2334945. Any opinions, findings, and conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p> <p>Copyright (c) 2021, Global Computing Lab</p>"},{"location":"Research/publications/","title":"Publications","text":"<ul> <li> Gabriel Laboy, Ian Lumsden, Jack Marquez, Kin Wai NG Lugo, Rodrigo Vargas, and Michela Taufer. A Modular, Cross-Platform Toolkit for High-Resolution Terrain Parameter Analysis. In Proceedings of the 21st IEEE International Conference on eScience (eScience), Chicago, IL, USA, September 2025. IEEE Computer Society. (Acceptance Rate: 33/98, 33.6%).</li> </ul> Bibtex <pre><code>@inproceedings{laboy2025modular_geotiled,\n  author    = {Gabriel Laboy and Ian Lumsden and Jack Marquez and Kin Wai NG Lugo and Rodrigo Vargas and Michela Taufer},\n  title     = {A Modular, Cross-Platform Toolkit for High-Resolution Terrain Parameter Analysis},\n  booktitle = {\\textit{Proceedings of the 21st IEEE International Conference on eScience (eScience)}},\n  address   = {Chicago, IL, USA},\n  month     = {September},\n  year      = {2025},\n  publisher = {IEEE Computer Society},\n  url       = {MISSING},\n  doi       = {MISSING}\n}\n</code></pre> <ul> <li> Gabriel Laboy, Paula Olaya, Jack Marquez, Michael Sutherlin, Rodrigo Vargas, and Michela Taufer.  Advancing the GEOtiled Framework Through Scalable Terrain Parameter Computation. In Proceedings of the 34th International Symposium on High-Performance Parallel and Distributed Computing (HPDC), pages 1\u20132, Notre Dame, IN, USA, July 20\u201323 2025. ACM. (Short Paper).</li> </ul> Bibtex <pre><code>@inproceedings{laboy2025advancing,  \n    author    = {Gabriel Laboy and Paula Olaya and Jack Marquez and Michael Sutherlin and Rodrigo Vargas and Michela Taufer},  \n    title     = {Advancing the GEOtiled Framework Through Scalable Terrain Parameter Computation},  \n    booktitle = {\\textit{Proceedings of the 34th International Symposium on High-Performance Parallel and Distributed Computing (HPDC)}},  \n    pages     = {1--2},  \n    address   = {Notre Dame, IN, USA},  \n    month     = {July 20--23},  \n    year      = {2025},  \n    publisher = {ACM}, \n    url       = {MISSING}, \n    doi       = {MISSING}  \n}\n</code></pre> <ul> <li> Befikir Bogale, Ian Lumsden, Dalal Sukkari, Dewi Yokelson, Stephanie Brink, Olga Pearce, and Michela Taufer.  Surrogate Models for Analyzing Performance Behavior of HPC Applications Using RAJAPerf. In Proceedings of the International Conference on Computational Science (ICCS), page 1\u20138, Singapore, July 7\u20139 2025. Springer.</li> </ul> Bibtex <pre><code>@inproceedings{bogale2025surrogate,  \n    author    = {Befikir Bogale and Ian Lumsden and Dalal Sukkari and Dewi Yokelson and Stephanie Brink and Olga Pearce and Michela Taufer},  \n    title     = {Surrogate Models for Analyzing Performance Behavior of HPC Applications Using RAJAPerf},  \n    booktitle = {\\textit{Proceedings of the International Conference on Computational Science (ICCS)}},  \n    pages     = {1--8},  \n    address   = {Singapore},  \n    month     = {July 7--9},  \n    year      = {2025},  \n    publisher = {Springer},  \n    url       = {https://doi.org/10.1007/978-3-031-97635-3_39},  \n    doi       = {doi.org/10.1007/978-3-031-97635-3_39}  \n}\n</code></pre> <ul> <li> Paula Olaya, Sophia Wen, Jay Lofstead, and Michela Taufer.  PerSSD: Persistent, Shared, and Scalable Data with Node-Local Storage for Scientific Workflows in Cloud Infrastructure. In Proceedings of the 2024 IEEE International Conference on Big Data, Washington DC, US, December 2024. IEEE Computer Society. (Acceptance Rate: 600/124, 18.8%).</li> </ul> Bibtex <pre><code>@inproceedings{olaya2024perssd,  \n    author    = {Paula Olaya and Sophia Wen and Jay Lofstead and Michela Taufer},  \n    title     = {PerSSD: Persistent, Shared, and Scalable Data with Node-Local Storage for Scientific Workflows in Cloud Infrastructure},  \n    booktitle = {\\textit{Proceedings of the 2024 IEEE International Conference on Big Data}},  \n    address   = {Washington DC, USA},  \n    month     = {December},  \n    year      = {2024},  \n    publisher = {IEEE Computer Society},  \n    url       = {https://doi.org/10.1109/BigData62323.2024.10826021},  \n    doi       = {10.1109/BigData62323.2024.10826021}  \n    }\n</code></pre> <ul> <li> Michela Taufer, Heberth Martinez, Aashish Panta, Paula Olaya, Jack Marquez, Amy Gooch, Giorgio Scorzelli, and Valerio Pascucci. Leveraging National Science Data Fabric Services to Train Data Scientists. In Proceedings of the 2024 Workshop on Education for HighPerformance Computing (EduHPC) Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis (SC24), Atlanta, GA, USA, November 2024. IEEE Computer Society.</li> </ul> Bibtex <pre><code>@inproceedings{taufer2024leveraging,  \n    author    = {Michela Taufer and Heberth Martinez and Aashish Panta and Paula Olaya and Jack Marquez and Amy Gooch and Giorgio Scorzelli and Valerio Pascucci},  \n    title     = {Leveraging National Science Data Fabric Services to Train Data Scientists},  \n    booktitle = {\\textit{Proceedings of the 2024 Workshop on Education for HighPerformance Computing (EduHPC) - Workshops of The International Conference on High Performance Computing, Network, Storage, and Analysis (SC24)}},  \n    address   = {Atlanta, GA, USA},  \n    month     = {November},  \n    year      = {2024},  \n    publisher = {IEEE Computer Society},  \n    doi       = {MISSING},  \n    url       = {MISSING}  \n}\n</code></pre> <ul> <li> Michela Taufer, Daniel Milroy, Todd Gamblin, Andrew Jones, Bill Magro, Heidi Poxon, and Seetharami Seelam. HPC and Cloud Convergence Beyond Technical Boundaries: Strategies for Economic Sustainability, Standardization, and Data Accessibility. IEEE Computer, 2024.</li> </ul> Bibtex <pre><code>@article{taufer2024hpc,  \n    author  = {Michela Taufer and Daniel Milroy and Todd Gamblin and Andrew Jones and Bill Magro and Heidi Poxon and Seetharami Seelam},  \n    title   = {HPC and Cloud Convergence Beyond Technical Boundaries: Strategies for Economic Sustainability, Standardization, and Data Accessibility},  \n    journal = {\\textit{IEEE Computer}},  \n    year    = {2024},  \n    doi     = {MISSING},  \n    url     = {MISSING}  \n}\n</code></pre> <ul> <li> Camila Roa, Mats Rynge, Paula Olaya, Karan Vahi, Todd Miller, John Goodhue, James Griffioen, David Hudak, Shelley Knuth, Ricardo Llamas, Rodrigo Vargas, Miron Livny, Ewa Deelman, and Michela Taufer. End-to-end Integration of Scientific Workflows on Distributed Cyberinfrastructures: Challenges and Lessons Learned with an Earth Science Application. In Proceedings of the 15th IEEE/ACM International Conference on Utility and Cloud Computing (UCC),pages 1\u201310, Taormina (Messina), Italy, December 2023. IEEE Computer Society. (Acceptance Rate: 20/50, 40%).</li> </ul> Bibtex <pre><code>@inproceedings{roa2023endtoend,  \n    author    = {Camila Roa and Mats Rynge and Paula Olaya and Karan Vahi and Todd Miller and John Goodhue and James Griffioen and David Hudak and Shelley Knuth and Ricardo Llamas and Rodrigo Vargas and Miron Livny and Ewa Deelman and Michela Taufer},  \n    title     = {End-to-end Integration of Scientific Workflows on Distributed Cyberinfrastructures: Challenges and Lessons Learned with an Earth Science Application},  \n    booktitle = {\\textit{Proceedings of the 15th IEEE/ACM International Conference on Utility and Cloud Computing (UCC)}},  \n    pages     = {1--10},  \n    address   = {Taormina (Messina), Italy},  \n    month     = {December},  \n    year      = {2023},  \n    publisher = {IEEE Computer Society},  \n    doi       = {MISSING},  \n    url       = {MISSING}  \n}\n</code></pre> <ul> <li> Camila Roa, Paula Olaya, Ricardo Llamas, Rodrigo Vargas, and Michela Taufer. GEOtiled: A Scalable Workflow for Generating Large Datasets of High-Resolution Terrain Parameters. Poster presented at the 32nd International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC), pages 1\u20132, Orlando, Florida, USA, Jun 2023.</li> </ul> Bibtex <pre><code>@inproceedings{roa2023geotiled,  \n    author    = {Camila Roa},  \n    title     = {GEOtiled: A Scalable Workflow for Generating Large Datasets of High-Resolution Terrain Parameters},  \n    booktitle = {\\textit{Poster presented at the 32nd International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC)}},  \n    pages     = {1--2},  \n    address   = {Orlando, Florida, USA},  \n    month     = {June},  \n    year      = {2023},  \n    doi       = {MISSING},  \n    url       = {MISSING}  \n}\n</code></pre> <ul> <li> Paula Olaya, Dominic Kennedy, Ricardo Llamas, Leobardo Valera, Rodrigo Vargas, Jay Lofstead, and Michela Taufer. Building Trust in Earth Science Findings through Data Traceability and Results Explainability. IEEE Transactions on Parallel and Distributed Systems</li> </ul> Bibtex <pre><code>@article{9942337,\n    author={Olaya, Paula and Kennedy, Dominic and Llamas, Ricardo and Valera, Leobardo and Vargas, Rodrigo\n    and Lofstead, Jay and Taufer, Michela},\n    journal={IEEE Transactions on Parallel and Distributed Systems},  \n    title={Building Trust in Earth Science Findings through Data Traceability and Results Explainability},\n    year={2023}, \n    volume={34}, \n    number={2}, \n    pages={704-717}, \n    doi={10.1109/TPDS.2022.3220539} \n    }\n</code></pre> <ul> <li> Paula Olaya, Jakob Luettgau, Camila Roa, Ricardo Llamas, Rodrigo Vargas, Sophia Wen, I-Hsin Chung, Seetharami Seelam, Yoonho Park, Jay Lofstead, and Michela Taufer. Enabling Scalability in the Cloud for Scientific Workflows: An Earth Science Use Case. IEEE International Conference on Cloud Computing 2023</li> </ul> Bibtex <pre><code>@INPROCEEDINGS{10255013, \n    author={Olaya, Paula and Luettgau, Jakob and Roa, Camila and Llamas, Ricardo and Vargas, Rodrigo and\n    Wen, Sophia and Chung, I-Hsin and Seelam, Seetharami and Park, Yoonho and Lofstead, Jay and Taufer,\n    Michela}, \n    booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)},  \n    title={Enabling Scalability in the Cloud for Scientific Workflows: An Earth Science Use Case},  \n    year={2023}, \n    pages={383-393}, \n    doi={10.1109/CLOUD60044.2023.00052}} \n</code></pre> <ul> <li> Danny Rorabaugh, Mario Guevara, Ricardo Llamas, Joy Kitson, Rodrigo Vargas, and Michela Taufer SOMOSPIE: A Modular SOil MOisture SPatial Inference Engine Based on Data-Driven Decisions 2019 15th International Conference on eScience (eScience)</li> </ul> Bibtex <pre><code>@inproceedings{rorabaugh2019somospie, \n    author = {Rorabaugh, Danny and Guevara, Mario and Llamas, Ricardo and Kitson, Joy and Vargas,\n    Rodrigo\n    and Taufer, Michela}, \n    title = {{SOMOSPIE: A modular SOil MOisture SPatial Inference Engine based on data-driven\n    decisions}}, \n    booktitle = {Proceedings of the 2019 15th International Conference on eScience (eScience)}, \n    pages = {1--10}, \n    year = {2019}, \n    organization = {IEEE Computer Society} \n    }\n</code></pre>"}]}